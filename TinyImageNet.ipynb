{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This code was used for experiments as-is. the code was ran in Enviornment 1: Kaggle as described in the paper\n",
    "# Naming and structure may not follow programming best practices.\n",
    "# Focus is on reproducibility.\n",
    "#This code was developed for internal experimentation and contains hardcoded values for various test cases.\n",
    "#It was not refactored for modularity, but the logic matches the experiments reported in the paper.\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet34\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    print(seed)\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "#set_all_seeds(40)\n",
    "#set_all_seeds(41)\n",
    "set_all_seeds(42)\n",
    "#set_all_seeds(43)\n",
    "#set_all_seeds(44)\n",
    "#set_all_seeds(45)\n",
    "#set_all_seeds(46)\n",
    "#set_all_seeds(47)\n",
    "#set_all_seeds(48)\n",
    "#set_all_seeds(49)\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TinyImageNet(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split='train', transform=None, download=False):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        if download:\n",
    "            self.download()\n",
    "        \n",
    "        self.data_dir = os.path.join(root, 'tiny-imagenet-200')\n",
    "        self.split_dir = os.path.join(self.data_dir, split)\n",
    "        \n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        self.classes = []\n",
    "        \n",
    "        if split == 'train':\n",
    "            self._load_train_data()\n",
    "        else:\n",
    "            self._load_val_data()\n",
    "    \n",
    "    def download(self):\n",
    "        if not os.path.exists(os.path.join(self.root, 'tiny-imagenet-200')):\n",
    "            # Create data directory if it doesn't exist\n",
    "            os.makedirs(self.root, exist_ok=True)\n",
    "            print(\"Downloading Tiny ImageNet...\")\n",
    "            url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "            zip_path = os.path.join(self.root, \"tiny-imagenet-200.zip\")\n",
    "            urllib.request.urlretrieve(url, zip_path)\n",
    "            \n",
    "            print(\"Extracting...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.root)\n",
    "            os.remove(zip_path)\n",
    "    \n",
    "    def _load_train_data(self):\n",
    "        class_dirs = sorted(os.listdir(self.split_dir))\n",
    "        self.classes = class_dirs\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_dirs)}\n",
    "        \n",
    "        for class_name in class_dirs:\n",
    "            class_dir = os.path.join(self.split_dir, class_name, 'images')\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith('.JPEG'):\n",
    "                        self.samples.append(os.path.join(class_dir, img_name))\n",
    "                        self.targets.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def _load_val_data(self):\n",
    "        # Load class names from train directory\n",
    "        train_dir = os.path.join(self.data_dir, 'train')\n",
    "        self.classes = sorted(os.listdir(train_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Read validation annotations\n",
    "        val_annotations = os.path.join(self.split_dir, 'val_annotations.txt')\n",
    "        with open(val_annotations, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                img_name, class_name = parts[0], parts[1]\n",
    "                self.samples.append(os.path.join(self.split_dir, 'images', img_name))\n",
    "                self.targets.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "# Define transforms for Tiny ImageNet (64x64 images)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(64, padding=8),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transformtest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_data = TinyImageNet(root='./data', split='train', transform=transform, download=True)\n",
    "test_data = TinyImageNet(root='./data', split='val', transform=transformtest, download=False)\n",
    "\n",
    "# Create DataLoaders for batching with increased batch size for efficiency\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Example: Accessing the dataset\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch of images shape: {images.shape}')\n",
    "    print(f'Batch of labels: {labels}')\n",
    "    print(f'Number of classes: {len(train_data.classes)}')\n",
    "    break\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class idle(nn.Module):\n",
    "    def forward(self, x):\n",
    "         #return x * torch.sigmoid(x)  #Swish\n",
    "         #return 1.25*x * torch.sigmoid(x) #ESwish(UP)\n",
    "         #return x*(torch.sigmoid(x)+0.125*torch.exp(-0.5*x**2))  #SwishPlus(UP)\n",
    "         #return x * torch.tanh(F.softplus(x))   #Mish\n",
    "         #return x * torch.tanh(F.softplus(0.9454113159514*x)/0.9454113159514)  #PMish(UP)\n",
    "         #return x * torch.tanh(F.softplus(x)) +0.025*x*torch.exp(-0.5*x**2)  #MishPlus(UP)\n",
    "         #return torch.relu(x) #ReLU\n",
    "         #return F.gelu(x, approximate='tanh') #GeLU \n",
    "         return F.gelu(x, approximate='tanh') +0.125 * x * torch.exp(-0.5 * x**2) #GeLUPlus   \n",
    "# Define ResNet model for Tiny ImageNet\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=200, pretrained=False):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.resnet = resnet34(pretrained=pretrained)\n",
    "        # Keep conv1 as is for 64x64 images (works well with 7x7 kernel)\n",
    "        if pretrained:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "        self.replace_activations(self.resnet)\n",
    "\n",
    "    def replace_activations(self, module):\n",
    "        \"\"\"\n",
    "        Recursively replace all ReLU activations in the model,\n",
    "        including those inside Sequential blocks\n",
    "        \"\"\"\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.ReLU):\n",
    "                # Direct replacement of ReLU modules\n",
    "                new_activation = idle()\n",
    "                if isinstance(module, nn.Sequential):\n",
    "                    # For Sequential containers, we need to maintain the order\n",
    "                    module[int(name)] = new_activation\n",
    "                else:\n",
    "                    setattr(module, name, new_activation)\n",
    "            elif len(list(child.children())) > 0:\n",
    "                # If module has children, recurse into them\n",
    "                self.replace_activations(child)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Verification function to check if replacement worked\n",
    "def verify_activation_replacement(model):\n",
    "    \"\"\"\n",
    "    Verify that all ReLU activations have been replaced with Idle\n",
    "    \"\"\"\n",
    "    def check_module(module):\n",
    "        relu_count = 0\n",
    "        idle_count = 0\n",
    "        for child in module.modules():\n",
    "            if isinstance(child, nn.ReLU):\n",
    "                relu_count += 1\n",
    "            if isinstance(child, idle):\n",
    "                idle_count += 1\n",
    "        return relu_count, idle_count\n",
    "\n",
    "    relu_count, idle_count = check_module(model_idle)\n",
    "    print(f\"Found {relu_count} ReLU activations and {idle_count} Idle activations\")\n",
    "    assert relu_count == 0, \"Some ReLU activations were not replaced!\"\n",
    "    return idle_count > 0\n",
    "\n",
    "def calculate_batch_accuracy(outputs, labels):\n",
    "    \"\"\"Calculate accuracy for a single batch while in training mode\"\"\"\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    return (predicted == labels).sum().item() / labels.size(0)\n",
    "\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Training loop with proper metrics tracking\n",
    "model_idle = CustomResNet18().to(device)\n",
    "optimizer = optim.SGD(model_idle.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                    step_size=8,    # Decay LR every 8 epochs (more frequent for faster convergence)\n",
    "                                    gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "verify_activation_replacement(model_idle)\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs=25  # Reduced epochs for time efficiency\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model_idle.train()\n",
    "    running_train_loss = 0.0\n",
    "    running_train_acc = 0.0\n",
    "    num_train_batches = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} (Training)'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_idle(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Calculate batch accuracy while in training mode\n",
    "        batch_acc = calculate_batch_accuracy(outputs, labels)\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        running_train_acc += batch_acc\n",
    "        num_train_batches += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = running_train_loss / num_train_batches\n",
    "    avg_train_acc = running_train_acc / num_train_batches\n",
    "\n",
    "    # Testing phase\n",
    "    model_idle.eval()\n",
    "    running_test_loss = 0.0\n",
    "    running_test_acc = 0.0\n",
    "    num_test_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs} (Testing)'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_idle(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_acc = calculate_batch_accuracy(outputs, labels)\n",
    "\n",
    "            running_test_loss += loss.item()\n",
    "            running_test_acc += batch_acc\n",
    "            num_test_batches += 1\n",
    "\n",
    "    avg_test_loss = running_test_loss / num_test_batches\n",
    "    avg_test_acc = running_test_acc / num_test_batches\n",
    "\n",
    "    # Store metrics\n",
    "    train_accuracies.append(avg_train_acc)\n",
    "    test_accuracies.append(avg_test_acc)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print(f'Training Loss: {avg_train_loss:.4f}, Training Accuracy: {avg_train_acc:.4f}')\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
